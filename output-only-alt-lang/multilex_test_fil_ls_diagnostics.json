{"usage": {"fil": {"prompt_tokens": 752418, "completion_tokens": 498400, "total_tokens": 1250818}}, "model": "meta-llama/Llama-2-70b-chat-hf", "prompt_name": "only-alt-lang", "tagalog": true, "quantization": "4bit", "batch_size": 16, "seed": 42, "errors": [], "inference_time": 3027.1616803258657}
